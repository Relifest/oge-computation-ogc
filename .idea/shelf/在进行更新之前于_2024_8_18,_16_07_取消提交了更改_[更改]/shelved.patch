Index: src/main/scala/whu/edu/cn/config/GlobalConfig.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package whu.edu.cn.config\n\nimport org.yaml.snakeyaml.Yaml\n\nimport java.io.FileInputStream\nimport java.net.URL\nimport java.util\n\nobject GlobalConfig {\n  //  def main(args: Array[String]): Unit = {\n  //    loadConfig()\n  //  }\n\n  {\n    println(\"尝试通过配置文件初始化\")\n    loadConfig()\n  }\n\n\n  def loadConfig(): Unit = {\n    val yaml = new Yaml()\n    try {\n      //      val location: URL = GlobalConfig.getClass.getProtectionDomain.getCodeSource.getLocation\n      //      val inputStream = new FileInputStream(location.getPath + \"config.yaml\")\n\n      var inputStream = new FileInputStream(\"/home/ogeStorage/config.yaml\")\n      if (null == inputStream) {\n        return\n      }\n      val data: util.Map[String, Any] = yaml.load(inputStream).asInstanceOf[java.util.Map[String, Any]]\n      inputStream.close()\n\n      // 先这样写\n\n      // DagBootConf\n      DagBootConf.DAG_ROOT_URL = data.get(\"DagBootConf\").asInstanceOf[java.util.Map[String, String]].get(\"DAG_ROOT_URL\")\n\n\n      // PostgreSqlConf\n      PostgreSqlConf.POSTGRESQL_URL = data.get(\"PostgreSqlConf\").asInstanceOf[java.util.Map[String, String]].get(\"POSTGRESQL_URL\")\n      PostgreSqlConf.POSTGRESQL_DRIVER = data.get(\"PostgreSqlConf\").asInstanceOf[java.util.Map[String, String]].get(\"POSTGRESQL_DRIVER\")\n      PostgreSqlConf.POSTGRESQL_USER = data.get(\"PostgreSqlConf\").asInstanceOf[java.util.Map[String, String]].get(\"POSTGRESQL_USER\")\n      PostgreSqlConf.POSTGRESQL_PWD = data.get(\"PostgreSqlConf\").asInstanceOf[java.util.Map[String, String]].get(\"POSTGRESQL_PWD\")\n      PostgreSqlConf.POSTGRESQL_MAX_RETRIES = data.get(\"PostgreSqlConf\").asInstanceOf[java.util.Map[String, Int]].get(\"POSTGRESQL_MAX_RETRIES\")\n      PostgreSqlConf.POSTGRESQL_RETRY_DELAY = data.get(\"PostgreSqlConf\").asInstanceOf[java.util.Map[String, Int]].get(\"POSTGRESQL_RETRY_DELAY\")\n\n\n      // Others\n      Others.tmsPath = data.get(\"Others\").asInstanceOf[java.util.Map[String, String]].get(\"tmsPath\")\n      Others.jsonAlgorithms = data.get(\"Others\").asInstanceOf[java.util.Map[String, String]].get(\"jsonAlgorithms\")\n      Others.ontheFlyStorage = data.get(\"Others\").asInstanceOf[java.util.Map[String, String]].get(\"ontheFlyStorage\")\n      Others.jsonSavePath = data.get(\"Others\").asInstanceOf[java.util.Map[String, String]].get(\"jsonSavePath\")\n      Others.tempFilePath = data.get(\"Others\").asInstanceOf[java.util.Map[String, String]].get(\"tempFilePath\")\n\n\n      println(data)\n    } catch {\n      case e: Exception =>\n        e.printStackTrace()\n    }\n  }\n\n  object DagBootConf {\n    // dag-boot 服务根路径\n    var DAG_ROOT_URL: String = \"http://172.22.1.13:8085/oge-dag-22\"\n    var EDU_ROOT_URL: String = \"http://172.22.1.13:8085/oge-dag-22\"\n  }\n\n  object RedisConf {\n    // Redis 基础配置\n    final val JEDIS_HOST: String = \"125.220.153.26\"\n    final val JEDIS_PORT: Int = 6379\n    final val JEDIS_PWD: String = \"ypfamily608\"\n    // Redis 超时时间\n    final val REDIS_CACHE_TTL: Long = 2 * 60L\n  }\n\n  object MinioConf {\n    // MinIO 基础配置\n    final val MINIO_ENDPOINT: String = \"http://172.22.1.28:9006\"\n    final val MINIO_ACCESS_KEY: String = \"oge\"\n    final val MINIO_SECRET_KEY: String = \"ypfamily608\"\n    final val MINIO_BUCKET_NAME: String = \"ogebos\"\n    final val MINIO_HEAD_SIZE: Int = 5000000\n    final val MINIO_MAX_CONNECTIONS: Int = 10000\n  }\n\n  object BosConf{\n    //Bos基础配置\n    final val BOS_ENDPOINT: String = \"https://s3.bj.bcebos.com\"\n  }\n\n  object PostgreSqlConf {\n    // PostgreSQL 基础配置\n    var POSTGRESQL_URL: String = \"jdbc:postgresql://172.22.1.13:30865/oge\" // \"jdbc:postgresql://10.101.240.21:30865/oge\"\"jdbc:postgresql://125.220.153.23:30865/oge\"\n    var POSTGRESQL_DRIVER: String = \"org.postgresql.Driver\"\n    var POSTGRESQL_USER: String = \"oge\"\n    var POSTGRESQL_PWD: String = \"ypfamily608\"\n    var POSTGRESQL_MAX_RETRIES: Int = 3\n    var POSTGRESQL_RETRY_DELAY: Int = 500\n  }\n  // GcConst\n  object GcConf {\n    final val localDataRoot = \"/home/geocube/tomcat8/apache-tomcat-8.5.57/webapps/data/gdc_api/\"\n    final val httpDataRoot = \"http://125.220.153.26:8093/data/gdc_api/\"\n    final val localHtmlRoot = \"/home/geocube/tomcat8/apache-tomcat-8.5.57/webapps/html/\"\n    final val algorithmJson = \"/home/geocube/kernel/geocube-core/tb19/process_description.json\"\n\n\n    //landsat-8 pixel value in BQA band from USGS\n    final val cloudValueLs8: Array[Int] = Array(2800, 2804, 2808, 2812, 6896, 6900, 6904, 6908)\n    final val cloudShadowValueLs8: Array[Int] = Array(2976, 2980, 2984, 2988, 3008, 3012, 3016, 3020, 7072, 7076,\n      7080, 7084, 7104, 7108, 7112, 7116)\n  }\n  object QGISConf {\n    // PostgreSQL 基础配置\n    var QGIS_DATA: String = \"/mnt/storage/algorithmData/\"\n    var QGIS_ALGORITHMCODE: String = \"cd /mnt/storage/qgis/;\"\n    var QGIS_HOST: String = \"172.22.1.19\"\n    var QGIS_USERNAME: String = \"root\"\n    var QGIS_PASSWORD: String = \"Ypfamily608!\"\n    var QGIS_PORT: Int = 22\n  }\n  object OTBConf{\n    var OTB_DATA: String = \"/mnt/storage/otbData/algorithmData/\"\n    var OTB_ALGORITHMCODE: String = \"cd /mnt/storage/otbData/algorithmCodeByOTB/;\"\n    var OTB_DOCKERDATA : String = \"/tmp/otb/\"   // docker的临时目录\n    var OTB_HOST: String = \"172.22.1.19\"\n    var OTB_USERNAME: String = \"root\"\n    var OTB_PASSWORD: String = \"Ypfamily608!\"\n    var OTB_PORT: Int = 22\n  }\n\n  //TODO：改为私有云\n  object SAGAConf {\n    var SAGA_DATA: String = \"/mnt/storage/SAGA/sagaData/\"  // docker挂载目录\n    var SAGA_DOCKERDATA: String = \"/tmp/saga/\"   // docker的临时目录\n    var SAGA_HOST: String = \"172.22.1.19\"\n    var SAGA_USERNAME: String = \"root\"\n    var SAGA_PASSWORD: String = \"Ypfamily608!\"\n    var SAGA_PORT: Int = 22\n  }\n//定量遥感算法\n  object QuantConf {\n    var Quant_DataPath:String = \"/mnt/storage/htTeam/data/\"\n    var Quant_HOST: String = \"172.22.1.20\"\n    var Quant_USERNAME: String = \"root\"\n    var Quant_PASSWORD: String = \"Ypfamily608!\"\n    var Quant_PORT: Int = 22\n  }\n  // 第三方算子\n  object ThirdApplication {\n    final var THIRD_HOST: String = \"172.22.1.19\"\n    final var THIRD_USERNAME: String = \"root\"\n    final var THIRD_PASSWORD: String = \"Ypfamily608!\"\n    final var DOCKER_DATA: String = \"/home/dell/cppGDAL/\"\n    final var SERVER_DATA: String = \"/mnt/storage/dem/\"\n    final var THIRD_PORT: Int = 22\n  }\n\n  object Others {\n    //    final var thirdJson = \"src/main/scala/whu/edu/cn/jsonparser/third-algorithm-infos.json\" //存储第三方算子解析文件地址\n    final var thirdJson = \"/mnt/storage/data/third-algorithm-infos.json\"\n\n    final var jsonAlgorithms = \"/mnt/storage/algorithms_ogc.json\" //存储json解析文件地址\n    final var tempFilePath = \"/mnt/storage/temp/\" //各类临时文件的地址\n    final var sagatempFilePath = \"/mnt/storage/SAGA/sagaData/\" //SAGA各类临时文件的地址/mnt/storage/SAGA/sagaData\n    final var otbtempFilePath = \"/mnt/storage/otbData/algorithmData/\" //OTB各类临时文件的地址/mnt/storage/otbData/algorithmData/\n    final var tmsPath = \"http://111.37.195.68:8888/api/oge-tms-png/\" //tms服务url\n    final var tmsHost = \"172.22.1.19\" //tms服务ip\n    final var tomcatHost = \"172.22.1.12\"\n    final var tomcatHost_public = \"111.37.195.68\"\n    final var ontheFlyStorage = \"/mnt/storage/on-the-fly/\" //tms瓦片存储地址\n    final var jsonSavePath = \"/mnt/storage/algorithmData/\" //geojson临时存储地址\n    final var bucketName = \"ogebos\"\n    var platform = \"cc\"\n    final var hbaseHost = \"172.22.1.8:2181\"\n  }\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/whu/edu/cn/config/GlobalConfig.scala b/src/main/scala/whu/edu/cn/config/GlobalConfig.scala
--- a/src/main/scala/whu/edu/cn/config/GlobalConfig.scala	(revision 6708fb1f308d32fc9398f21ff322c30fa2156943)
+++ b/src/main/scala/whu/edu/cn/config/GlobalConfig.scala	(date 1723879072369)
@@ -62,13 +62,13 @@
 
   object DagBootConf {
     // dag-boot 服务根路径
-    var DAG_ROOT_URL: String = "http://172.22.1.13:8085/oge-dag-22"
-    var EDU_ROOT_URL: String = "http://172.22.1.13:8085/oge-dag-22"
+    var DAG_ROOT_URL: String = "http://10.126.35.188:8085/oge-dag-22"
+    var EDU_ROOT_URL: String = "http://10.126.35.188:8085/oge-dag-22"
   }
 
   object RedisConf {
     // Redis 基础配置
-    final val JEDIS_HOST: String = "125.220.153.26"
+    final val JEDIS_HOST: String = "10.126.35.188"
     final val JEDIS_PORT: Int = 6379
     final val JEDIS_PWD: String = "ypfamily608"
     // Redis 超时时间
@@ -77,9 +77,9 @@
 
   object MinioConf {
     // MinIO 基础配置
-    final val MINIO_ENDPOINT: String = "http://172.22.1.28:9006"
-    final val MINIO_ACCESS_KEY: String = "oge"
-    final val MINIO_SECRET_KEY: String = "ypfamily608"
+    final val MINIO_ENDPOINT: String = "http://10.126.35.215:9006"
+    final val MINIO_ACCESS_KEY: String = "minioadmin"
+    final val MINIO_SECRET_KEY: String = "minioadmin"
     final val MINIO_BUCKET_NAME: String = "ogebos"
     final val MINIO_HEAD_SIZE: Int = 5000000
     final val MINIO_MAX_CONNECTIONS: Int = 10000
@@ -92,7 +92,7 @@
 
   object PostgreSqlConf {
     // PostgreSQL 基础配置
-    var POSTGRESQL_URL: String = "jdbc:postgresql://172.22.1.13:30865/oge" // "jdbc:postgresql://10.101.240.21:30865/oge""jdbc:postgresql://125.220.153.23:30865/oge"
+    var POSTGRESQL_URL: String = "jdbc:postgresql://10.126.35.184:30865/oge" // "jdbc:postgresql://10.101.240.21:30865/oge""jdbc:postgresql://125.220.153.23:30865/oge"
     var POSTGRESQL_DRIVER: String = "org.postgresql.Driver"
     var POSTGRESQL_USER: String = "oge"
     var POSTGRESQL_PWD: String = "ypfamily608"
@@ -116,18 +116,18 @@
     // PostgreSQL 基础配置
     var QGIS_DATA: String = "/mnt/storage/algorithmData/"
     var QGIS_ALGORITHMCODE: String = "cd /mnt/storage/qgis/;"
-    var QGIS_HOST: String = "172.22.1.19"
-    var QGIS_USERNAME: String = "root"
-    var QGIS_PASSWORD: String = "Ypfamily608!"
+    var QGIS_HOST: String = "10.126.35.48"
+    var QGIS_USERNAME: String = "oge"
+    var QGIS_PASSWORD: String = "!Ypfamily"
     var QGIS_PORT: Int = 22
   }
   object OTBConf{
     var OTB_DATA: String = "/mnt/storage/otbData/algorithmData/"
     var OTB_ALGORITHMCODE: String = "cd /mnt/storage/otbData/algorithmCodeByOTB/;"
     var OTB_DOCKERDATA : String = "/tmp/otb/"   // docker的临时目录
-    var OTB_HOST: String = "172.22.1.19"
-    var OTB_USERNAME: String = "root"
-    var OTB_PASSWORD: String = "Ypfamily608!"
+    var OTB_HOST: String = "10.126.35.48"
+    var OTB_USERNAME: String = "oge"
+    var OTB_PASSWORD: String = "!Ypfamily!"
     var OTB_PORT: Int = 22
   }
 
@@ -162,18 +162,18 @@
     //    final var thirdJson = "src/main/scala/whu/edu/cn/jsonparser/third-algorithm-infos.json" //存储第三方算子解析文件地址
     final var thirdJson = "/mnt/storage/data/third-algorithm-infos.json"
 
-    final var jsonAlgorithms = "/mnt/storage/algorithms_ogc.json" //存储json解析文件地址
+    final var jsonAlgorithms = "/data/storage/algorithms_ogc.json" //存储json解析文件地址
     final var tempFilePath = "/mnt/storage/temp/" //各类临时文件的地址
     final var sagatempFilePath = "/mnt/storage/SAGA/sagaData/" //SAGA各类临时文件的地址/mnt/storage/SAGA/sagaData
     final var otbtempFilePath = "/mnt/storage/otbData/algorithmData/" //OTB各类临时文件的地址/mnt/storage/otbData/algorithmData/
-    final var tmsPath = "http://111.37.195.68:8888/api/oge-tms-png/" //tms服务url
-    final var tmsHost = "172.22.1.19" //tms服务ip
-    final var tomcatHost = "172.22.1.12"
-    final var tomcatHost_public = "111.37.195.68"
-    final var ontheFlyStorage = "/mnt/storage/on-the-fly/" //tms瓦片存储地址
-    final var jsonSavePath = "/mnt/storage/algorithmData/" //geojson临时存储地址
+    final var tmsPath = "http://10.126.35.188:8888/api/oge-tms-png/" //tms服务url
+    final var tmsHost = "10.126.35.48" //tms服务ip
+    final var tomcatHost = "10.126.35.188"
+    final var tomcatHost_public = "10.126.35.188"
+    final var ontheFlyStorage = "/data/oge/storage/on-the-fly/" //tms瓦片存储地址
+    final var jsonSavePath = "/data/oge/storage/algorithmData/" //geojson临时存储地址
     final var bucketName = "ogebos"
     var platform = "cc"
     final var hbaseHost = "172.22.1.8:2181"
   }
-}
\ No newline at end of file
+}
Index: src/main/scala/whu/edu/cn/util/SSHClientUtil.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package whu.edu.cn.util;\n\nimport com.jcraft.jsch.ChannelExec;\nimport com.jcraft.jsch.JSch;\nimport com.jcraft.jsch.Session;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.BufferedReader;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.nio.charset.Charset;\nimport java.util.Properties;\n\npublic class SSHClientUtil {\n    private static final Logger log = LoggerFactory.getLogger(SSHClientUtil.class);\n    private static ChannelExec channelExec;\n    private static Session session = null;\n    private static final int timeout = 60000;\n    /**\n     * 连接远程服务器\n     * @param host ip地址\n     * @param userName 登录名\n     * @param password 密码\n     * @param port 端口\n     * @throws Exception\n     */\n    public static void versouSshUtil(String host,String userName,String password,int port) throws Exception{\n        log.info(\"尝试连接到....host:\" + host + \",username:\" + userName + \",password:\" + password + \",port:\"\n                + port);\n        JSch jsch = new JSch(); // 创建JSch对象\n        session = jsch.getSession(userName, host, port); // 根据用户名，主机ip，端口获取一个Session对象\n        session.setPassword(password); // 设置密码\n        Properties config = new Properties();\n        config.put(\"StrictHostKeyChecking\", \"no\");\n        session.setConfig(config); // 为Session对象设置properties\n        session.setTimeout(timeout); // 设置timeout时间\n        session.connect(); // 通过Session建立链接\n    }\n    public static void versouSshUtil(String host) throws Exception{\n        log.info(\"尝试连接到....host:\" + host );\n        JSch jsch = new JSch(); // 创建JSch对象\n        session = jsch.getSession(host); // 根据用户名，主机ip，端口获取一个Session对象\n//        session.setPassword(password); // 设置密码\n        Properties config = new Properties();\n        config.put(\"StrictHostKeyChecking\", \"no\");\n        session.setConfig(config); // 为Session对象设置properties\n        session.setTimeout(timeout); // 设置timeout时间\n        session.connect(); // 通过Session建立链接\n    }\n\n    /**\n     * 在远程服务器上执行命令\n     * @param cmd 要执行的命令字符串\n     * @param charset 编码\n     * @throws Exception\n     */\n    public static void runCmd(String cmd,String charset) throws Exception{\n        channelExec = (ChannelExec) session.openChannel(\"exec\");\n        channelExec.setCommand(cmd);\n        channelExec.setInputStream(null);\n        channelExec.setErrStream(System.err);\n        channelExec.connect();\n        InputStream in = channelExec.getInputStream();\n        BufferedReader reader = new BufferedReader(new InputStreamReader(in, Charset.forName(charset)));\n        String buf = null;\n        while ((buf = reader.readLine()) != null){\n            System.out.println(buf);\n        }\n        reader.close();\n        channelExec.disconnect();\n        session.disconnect();\n    }\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/whu/edu/cn/util/SSHClientUtil.java b/src/main/scala/whu/edu/cn/util/SSHClientUtil.java
--- a/src/main/scala/whu/edu/cn/util/SSHClientUtil.java	(revision 6708fb1f308d32fc9398f21ff322c30fa2156943)
+++ b/src/main/scala/whu/edu/cn/util/SSHClientUtil.java	(date 1723879072373)
@@ -71,4 +71,4 @@
         channelExec.disconnect();
         session.disconnect();
     }
-}
\ No newline at end of file
+}
Index: src/main/scala/whu/edu/cn/oge/TriggerEdu.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package whu.edu.cn.oge\n\nimport geotrellis.layer.stitch.TileLayoutStitcher\nimport geotrellis.layer.{SpaceTimeKey, SpatialKey, TileLayerMetadata}\nimport geotrellis.proj4.CRS\nimport geotrellis.raster.{MultibandTile, Raster}\nimport geotrellis.raster.io.geotiff.GeoTiff\nimport org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.rdd.RDD\nimport whu.edu.cn.entity.SpaceTimeBandKey\nimport whu.edu.cn.oge.Coverage.reproject\nimport whu.edu.cn.util.RDDTransformerUtil.makeChangedRasterRDDFromTif\nimport java.nio.file.Paths\n\nimport org.apache.spark.ml.PipelineModel\nimport org.apache.spark.sql.SparkSession\nimport whu.edu.cn.algorithms.MLlib._\n\nimport scala.util.Random\nimport org.jpmml.sparkml.PMMLBuilder\nimport org.jpmml.sparkml.PipelineModelUtil\nimport java.io.{File, IOException}\n\nimport com.google.common.io.{MoreFiles, RecursiveDeleteOption}\n\nobject TriggerEdu {\n  def makeTIFF(coverage: (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]), outputPath: String): Unit = {\n    val coverageArray: Array[(SpatialKey, MultibandTile)] = coverage._1.map(t => {\n      (t._1.spaceTimeKey.spatialKey, t._2)\n    }).collect()\n\n    val (tile, (_, _), (_, _)) = TileLayoutStitcher.stitch(coverageArray)\n    val stitchedTile: Raster[MultibandTile] = Raster(tile, coverage._2.extent)\n    GeoTiff(stitchedTile, coverage._2.crs).write(outputPath)\n\n  }\n  def reprojectEdu(implicit sc: SparkContext, inputPath: String, outputPath: String, Crs: String, scale: Double) = {\n    val epsg: Int = Crs.split(\":\")(1).toInt\n    val crs: CRS = CRS.fromEpsgCode(epsg)\n    val coverage1: (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]) = makeChangedRasterRDDFromTif(sc, inputPath)\n    val coverage2 = reproject(coverage1, crs, scale)\n    makeTIFF(coverage2, outputPath)\n    println(\"SUCCESS\")\n  }\n  def randomForestTrain(implicit sc: SparkContext, featuresPath: String, labelPath: String, modelOutputPath: String, labelCol: Int = 0, checkpointInterval: Int = 10, featureSubsetStrategy: String = \"auto\", maxBins: Int = 32, maxDepth: Int = 5, minInfoGain: Double = 0.0, minInstancesPerNode:Int = 1, minWeightFractionPerNode: Double = 0.0, numTrees: Int = 20, seed: Long = Random.nextLong(), subsamplingRate: Double = 1.0) = {\n    val spark = SparkSession.builder().config(sc.getConf).getOrCreate()\n    val featursCoverage: (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]) = makeChangedRasterRDDFromTif(sc, featuresPath)\n    val labelCoverage: (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]) = makeChangedRasterRDDFromTif(sc, labelPath)\n\n    val model: PipelineModel = Classifier.randomForest(checkpointInterval, featureSubsetStrategy, maxBins, maxDepth, minInfoGain, minInstancesPerNode, minWeightFractionPerNode, numTrees, seed, subsamplingRate)\n      .train(spark, featursCoverage, labelCoverage, labelCol)\n    val file: File = new File(modelOutputPath)\n    file.createNewFile()\n    val tmpDir = File.createTempFile(\"PipelineModel\", \"\")\n    if (!tmpDir.delete) throw new IOException\n    else {\n      PipelineModelUtil.store(model, tmpDir)\n      PipelineModelUtil.compress(tmpDir, file)\n      tmpDir.delete()\n    }\n    println(\"SUCCESS\")\n  }\n  def classify(implicit sc: SparkContext, featuresPath: String, modelPath: String, classifiedOutputPath: String): Unit = {\n    val spark = SparkSession.builder().config(sc.getConf).getOrCreate()\n    val featursCoverage: (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]) = makeChangedRasterRDDFromTif(sc, featuresPath)\n    val file: File = new File(modelPath)\n    val tmpDir: File = PipelineModelUtil.uncompress(file)\n    val model: PipelineModel = PipelineModelUtil.load(spark, tmpDir)\n    val predictedCoverage = Classifier.classify(spark, featursCoverage, model)(\"prediction\")\n    tmpDir.delete()\n    makeTIFF(predictedCoverage, classifiedOutputPath)\n    println(\"SUCCESS\")\n  }\n\n  def main(args: Array[String]): Unit = {\n    val conf: SparkConf = new SparkConf().setAppName(\"New Coverage\").setMaster(\"local[*]\")\n    val sc = new SparkContext(conf)\n    //    reprojectEdu(sc, \"/D:/TMS/07-29-2024-09-25-29_files_list/LC08_L1TP_002017_20190105_20200829_02_T1_B1.tif\", \"/D:/TMS/07-29-2024-09-25-29_files_list/LC08_L1TP_002017_20190105_20200829_02_T1_B1_reprojected.tif\", \"EPSG:3857\", 100)\n//    randomForestTrain(sc, \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\毕设\\\\应用_监督分类结果\\\\RGB_Mean.tif\", \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\oge\\\\OGE竞赛\\\\features4label.tif\", \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\oge\\\\OGE竞赛\\\\out\\\\model0817new.zip\", 4)\n    classify(sc, \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\毕设\\\\应用_监督分类结果\\\\RGB_Mean.tif\", \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\oge\\\\OGE竞赛\\\\out\\\\model0817new.zip\", \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\oge\\\\OGE竞赛\\\\out\\\\result.tif\")\n  }\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/whu/edu/cn/oge/TriggerEdu.scala b/src/main/scala/whu/edu/cn/oge/TriggerEdu.scala
--- a/src/main/scala/whu/edu/cn/oge/TriggerEdu.scala	(revision 6708fb1f308d32fc9398f21ff322c30fa2156943)
+++ b/src/main/scala/whu/edu/cn/oge/TriggerEdu.scala	(date 1723967993768)
@@ -23,6 +23,14 @@
 
 import com.google.common.io.{MoreFiles, RecursiveDeleteOption}
 
+import org.apache.hadoop.conf.Configuration
+import org.apache.hadoop.fs.{FileSystem, Path, RemoteIterator, LocatedFileStatus}
+import java.io.{BufferedOutputStream, ByteArrayOutputStream, InputStream}
+import java.util.zip.{ZipEntry, ZipOutputStream}
+
+
+
+
 object TriggerEdu {
   def makeTIFF(coverage: (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]), outputPath: String): Unit = {
     val coverageArray: Array[(SpatialKey, MultibandTile)] = coverage._1.map(t => {
@@ -60,6 +68,51 @@
     }
     println("SUCCESS")
   }
+
+  def compress(dir: String, zipdir: String): Unit = {
+    val conf = new Configuration()
+    val hdfs = FileSystem.get(new java.net.URI(dir), conf)
+
+    val dirPath = new Path(dir)
+    val zipPath = new Path(zipdir)
+
+    val zos = new ZipOutputStream(new BufferedOutputStream(hdfs.create(zipPath)))
+
+    try {
+      val fileStatusListIterator: RemoteIterator[LocatedFileStatus] = hdfs.listFiles(dirPath, true)
+
+      while (fileStatusListIterator.hasNext) {
+        val fileStatus = fileStatusListIterator.next()
+        val filePath = fileStatus.getPath
+        val relativePath = dirPath.toUri.relativize(filePath.toUri).getPath
+
+        val entry = new ZipEntry(relativePath)
+        entry.setSize(fileStatus.getLen)
+        entry.setTime(fileStatus.getModificationTime)
+
+        zos.putNextEntry(entry)
+
+        val is: InputStream = hdfs.open(filePath)
+        try {
+          val buffer = new Array
+          var len = is.read(buffer)
+          while (len > 0) {
+            zos.write(buffer, 0, len)
+            len = is.read(buffer)
+          }
+        } finally {
+          is.close()
+        }
+
+        zos.closeEntry()
+      }
+
+      zos.finish()
+    } finally {
+      zos.close()
+    }
+  }
+
   def classify(implicit sc: SparkContext, featuresPath: String, modelPath: String, classifiedOutputPath: String): Unit = {
     val spark = SparkSession.builder().config(sc.getConf).getOrCreate()
     val featursCoverage: (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]) = makeChangedRasterRDDFromTif(sc, featuresPath)
Index: src/main/scala/whu/edu/cn/oge/Feature.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package whu.edu.cn.oge\n\nimport java.io.{BufferedWriter, File, FileWriter, PrintWriter}\nimport com.alibaba.fastjson.{JSON, JSONArray, JSONObject}\nimport org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.rdd.RDD\nimport org.locationtech.jts.geom.{Coordinate, CoordinateSequence, Geometry, Point}\nimport org.locationtech.jts.io.WKTReader\nimport whu.edu.cn.geocube.util.HbaseUtil._\n\nimport java.sql.ResultSet\nimport java.text.SimpleDateFormat\nimport java.util\nimport java.util.{Date, UUID}\nimport geotrellis.layer.stitch.TileLayoutStitcher\nimport geotrellis.layer.{Bounds, LayoutDefinition, Metadata, SpaceTimeKey, SpatialKey, TileLayerMetadata}\nimport geotrellis.proj4\nimport geotrellis.raster.{DoubleCellType, DoubleConstantNoDataCellType, MultibandTile, PixelIsPoint, Raster, RasterExtent, Tile, TileLayout, mask}\nimport geotrellis.vector\nimport geotrellis.vector.interpolation.{NonLinearSemivariogram, Semivariogram, Spherical}\nimport geotrellis.vector.{Extent, PointFeature, interpolation}\nimport org.geotools.referencing.CRS\nimport geotrellis.spark._\nimport geotrellis.raster.interpolation._\nimport geotrellis.raster.io.geotiff.GeoTiff\nimport geotrellis.raster.rasterize.Rasterizer\nimport geotrellis.raster.rasterize.Rasterizer.Options\nimport geotrellis.raster.render.{ColorRamp, ColorRamps}\nimport io.minio.GetObjectArgs\nimport whu.edu.cn.geocube.core.entity\nimport org.apache.commons.lang3.StringUtils\nimport org.apache.commons.logging.{Log, LogFactory}\nimport whu.edu.cn\nimport whu.edu.cn.config.GlobalConfig\nimport whu.edu.cn.config.GlobalConfig.DagBootConf.DAG_ROOT_URL\nimport whu.edu.cn.debug.CoverageDubug.makeTIFF\nimport whu.edu.cn.debug.FeatureDebug.saveFeatureRDDToShp\nimport whu.edu.cn.entity.SpaceTimeBandKey\nimport whu.edu.cn.trigger.Trigger\nimport whu.edu.cn.util.HttpRequestUtil.sendPost\nimport whu.edu.cn.util.SSHClientUtil.{runCmd, versouSshUtil}\nimport whu.edu.cn.util.{MinIOUtil, PostSender, PostgresqlUtil}\n\nimport java.nio.file.Paths\nimport com.baidubce.services.bos.model.GetObjectRequest\n\nimport java.nio.file.StandardCopyOption.REPLACE_EXISTING\nimport scala.collection.mutable\nimport scala.collection.mutable.ListBuffer\nimport scala.collection.mutable.Map\nimport scala.io.Source\nimport scala.math.{max, min}\nimport scala.sys.process._\n\nobject Feature {\n  def load(implicit sc: SparkContext, productName: String = null, dataTime: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    var crs1 = crs\n    if (crs == null)\n      crs1 = \"EPSG:4326\"\n    val t1 = System.currentTimeMillis()\n    val queryRes = query(productName)\n    val t2 = System.currentTimeMillis()\n    println(\"从pgsql查询元数据的时间：\" + (t2 - t1))\n    val metaData = queryRes._3\n    val hbaseTableName = queryRes._2\n    val productKey = queryRes._1\n//    println(metaData)\n//    println(hbaseTableName)\n//    println(productKey)\n    //    if(dataTime==null){\n    //      val geometryRdd = sc.makeRDD(metaData).map(t=>t.replace(\"List(\", \"\").replace(\")\", \"\").split(\",\"))\n    //        .flatMap(t=>t)\n    //        .map(t=>(t, getVectorWithRowkey(hbaseTableName,t)))\n    //      geometryRdd.map(t=>{\n    //        t._2._1.setSRID(crs.split(\":\")(1).toInt)\n    //        t\n    //      })\n    //    }\n    var prefix = \"\"\n    if (dataTime == null) {\n      prefix = productKey\n    }\n    else {\n      prefix = productKey + \"_\" + dataTime\n    }\n    val t3 = System.currentTimeMillis()\n    val geometryRdd = getVectorWithPrefixFilter(sc, hbaseTableName, prefix).map(t => {\n      t._2._1.setSRID(crs1.split(\":\")(1).toInt)\n      t\n    })\n    val t4 = System.currentTimeMillis()\n    println(\"从hbase加载数据的时间：\" + (t4 - t3))\n    geometryRdd\n  }\n\n  //返回productKey,hbaseTableName,rowkeyList\n  def query(productName: String = null): (String, String, ListBuffer[String]) = {\n    val metaData = ListBuffer.empty[String]\n    var hbaseTableName = \"\"\n    var productKey = \"\"\n    val postgresqlUtil = new PostgresqlUtil(\"\")\n    val conn = postgresqlUtil.getConnection\n    if (conn != null) {\n      try {\n        // Configure to be Read Only\n        val statement = conn.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE, ResultSet.CONCUR_READ_ONLY)\n\n        // Extent dimension\n        val sql = new StringBuilder\n        sql ++= \"select oge_data_resource_product.name, oge_vector_fact.fact_data_ids, oge_vector_fact.table_name, oge_vector_fact.product_key \" +\n          \"from oge_vector_fact join oge_data_resource_product \" +\n          \"on oge_vector_fact.product_key= oge_data_resource_product.id where \"\n        if (productName != \"\" && productName != null) {\n          sql ++= \"name = \" + \"'\" + productName + \"'\"\n        }\n        println(sql)\n        val extentResults = statement.executeQuery(sql.toString())\n\n\n        while (extentResults.next()) {\n          val factDataIDs = extentResults.getString(\"fact_data_ids\")\n          metaData.append(factDataIDs)\n          productKey = extentResults.getString(\"product_key\")\n          hbaseTableName = extentResults.getString(\"table_name\")\n        }\n      }\n      finally {\n        conn.close\n      }\n    } else throw new RuntimeException(\"connection failed\")\n    (productKey, hbaseTableName, metaData)\n  }\n\n  def getVectorWithRowkey(hbaseTableName: String, rowKey: String): (Geometry, Map[String, Any]) = {\n    val t1 = System.currentTimeMillis()\n    val meta = getVectorMeta(hbaseTableName, rowKey, \"vectorData\", \"metaData\")\n    val cell = getVectorCell(hbaseTableName, rowKey, \"vectorData\", \"geom\")\n    //    println(meta)\n    //    println(cell)\n    println(cell)\n    val t2 = System.currentTimeMillis()\n    println(\"根据rowkey取数据时间：\" + (t2 - t1) / 1000)\n    val jsonObject = JSON.parseObject(meta)\n    val properties = jsonObject.getJSONArray(\"properties\").getJSONObject(0)\n    val propertiesOut = Map.empty[String, Any]\n    val sIterator = properties.keySet.iterator\n    while (sIterator.hasNext()) {\n      val key = sIterator.next();\n      val value = properties.getString(key);\n      propertiesOut += (key -> value)\n    }\n    val reader = new WKTReader()\n    val geometry = reader.read(cell)\n    (geometry, propertiesOut)\n  }\n\n  def getVectorWithPrefixFilter(implicit sc: SparkContext, hbaseTableName: String, prefix: String): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val t1 = System.currentTimeMillis()\n    val queryData = getVectorWithPrefix(hbaseTableName, prefix)\n    println(queryData.length)\n    val t2 = System.currentTimeMillis()\n    println(\"取数据执行了！\")\n    println(\"getVectorWithPrefix时间：\" + (t2 - t1))\n    val rawRDD = sc.parallelize(queryData)\n    rawRDD.map(t => {\n      val rowkey = t._1\n      val geomStr = t._2._1\n      val meta = t._2._2\n      val userData = t._2._3\n      val reader = new WKTReader()\n      val geometry = reader.read(geomStr)\n      val jsonobject: JSONObject = JSON.parseObject(meta)\n      val prop = jsonobject.getJSONArray(\"properties\").getJSONObject(0).toString\n      val metaMap = getMapFromJsonStr(prop)\n      val userMap = getMapFromJsonStr(userData)\n      (rowkey, (geometry, metaMap ++ userMap))\n    })\n  }\n\n  /**\n   * create a Point, and take the point in RDD\n   *\n   * @param sc         used to create RDD\n   * @param coors      coordinates to create geometry\n   * @param properties properties for geometry,it is a json String\n   * @param crs        projection of geometry\n   * @return\n   */\n  def point(implicit sc: SparkContext, coors: String, properties: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom = Geometry.point(coors, crs)\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromStr(properties)))\n    })\n  }\n\n  private def getMapFromStr(str: String): Map[String, Any] = {\n    val map = Map.empty[String, Any]\n    val keyValuePairs = str.stripPrefix(\"{\").stripSuffix(\"}\").split(',')\n    keyValuePairs.foreach { pair =>\n      val keyValue = pair.split(':')\n      if (keyValue.length == 2) {\n        val key = keyValue(0).trim\n        val value = keyValue(1).trim\n        map += (key -> value)\n      }\n    }\n    map\n  }\n\n  /**\n   * create a LineString, and take the LineString in RDD\n   *\n   * @param sc         used to create RDD\n   * @param coors      coordinates to create geometry\n   * @param properties properties for geometry,it is a json String\n   * @param crs        projection of geometry\n   * @return\n   */\n  def lineString(implicit sc: SparkContext, coors: String, properties: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom = Geometry.lineString(coors, crs)\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromStr(properties)))\n    })\n  }\n\n  /**\n   * create a LinearRing, and take the LinearRing in RDD\n   *\n   * @param sc         used to create RDD\n   * @param coors      coordinates to create geometry\n   * @param properties properties for geometry,it is a json String\n   * @param crs        projection of geometry\n   * @return\n   */\n  def linearRing(implicit sc: SparkContext, coors: String, properties: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom = Geometry.linearRing(coors, crs)\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromJsonStr(properties)))\n    })\n  }\n\n  /**\n   * create a Polygon, and take the Polygon in RDD\n   *\n   * @param sc         used to create RDD\n   * @param coors      coordinates to create geometry\n   * @param properties properties for geometry,it is a json String\n   * @param crs        projection of geometry\n   * @return\n   */\n  def polygon(implicit sc: SparkContext, coors: String, properties: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom = Geometry.polygon(coors, crs)\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromStr(properties)))\n    })\n  }\n\n  /**\n   * create a MultiPoint, and take the MultiPoint in RDD\n   *\n   * @param sc         used to create RDD\n   * @param coors      coordinates to create geometry\n   * @param properties properties for geometry,it is a json String\n   * @param crs        projection of geometry\n   * @return\n   */\n  def multiPoint(implicit sc: SparkContext, coors: String, properties: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom = Geometry.multiPoint(coors, crs)\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromJsonStr(properties)))\n    })\n  }\n\n  /**\n   * create a MultiLineString, and take the MultiLineString in RDD\n   *\n   * @param sc         used to create RDD\n   * @param coors      coordinates to create geometry\n   * @param properties properties for geometry,it is a json String\n   * @param crs        projection of geometry\n   * @return\n   */\n  def multiLineString(implicit sc: SparkContext, coors: String, properties: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom = Geometry.multiLineString(coors, crs)\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromJsonStr(properties)))\n    })\n  }\n\n  /**\n   * create a MultiPolygon, and take the MultiPolygon in RDD\n   *\n   * @param sc         used to create RDD\n   * @param coors      coordinates to create geometry\n   * @param properties properties for geometry,it is a json String\n   * @param crs        projection of geometry\n   * @return\n   */\n  def multiPolygon(implicit sc: SparkContext, coors: String, properties: String = null, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom = Geometry.multiPolygon(coors, crs)\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromJsonStr(properties)))\n    })\n  }\n\n  /**\n   * create a geometry, and take the geometry in RDD\n   *\n   * @param sc         used to create RDD\n   * @param gjson      to create geometry\n   * @param crs        projection of geometry\n   * @return\n   */\n\n  def geometry(implicit sc: SparkContext, gjson: String, crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    //异常处理，报错信息统一格式\n    val escapedJson = gjson.replace(\"\\\\\", \"\")//去除转义符\n    val jsonobject: JSONObject = JSON.parseObject(escapedJson)\n    val array = jsonobject.getJSONArray(\"features\")\n    var list: List[(Geometry, String)] = List.empty\n    for (i <- 0 until (array.size())) {\n      val geom = Geometry.geometry(array.getJSONObject(i), crs)\n      list = list :+ (geom, array.getJSONObject(i).get(\"properties\").toString)\n    }\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t._1, getMapFromJsonStr(t._2)))\n    })\n  }\n\n  def feature(implicit sc: SparkContext, geom: Geometry, properties: String = null): RDD[(String, (Geometry, Map[String, Any]))] = {\n    var list: List[Geometry] = List.empty\n    list = list :+ geom\n    val geomRDD = sc.parallelize(list)\n    geomRDD.map(t => {\n      (UUID.randomUUID().toString, (t, getMapFromJsonStr(properties)))\n    })\n  }\n\n  def featureCollection(implicit sc: SparkContext, featureList: List[RDD[(String, (Geometry, Map[String, Any]))]]): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val len = featureList.length\n    var featureCollectionRDD = featureList(0)\n    for (a <- 1 until len) {\n      featureCollectionRDD = featureCollectionRDD.union(featureList(a))\n    }\n    featureCollectionRDD\n  }\n\n  /**\n   * transform json to Map[k,v]\n   *\n   * @param json the json to operate\n   * @return\n   */\n  def getMapFromJsonStr(json: String): Map[String, Any] = {\n    val map = Map.empty[String, Any]\n    if (StringUtils.isNotEmpty(json) && !json.equals(\"\")) {\n      val jsonObject = JSON.parseObject(json)\n      val sIterator = jsonObject.keySet.iterator\n      while (sIterator.hasNext()) {\n        val key = sIterator.next()\n        val value = jsonObject.get(key)\n        map += (key -> value)\n      }\n    }\n    map\n  }\n\n  /**\n   * get area of the feature RDD.\n   *\n   * @param featureRDD the feature RDD to compute\n   * @param crs        the crs for compute area\n   * @return\n   */\n  def area(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:3857\"): String = {\n    featureRDD.map(t => Geometry.area(t._2._1, crs)).collect().toList.mkString(\",\")\n  }\n\n  /**\n   * Returns the bounding rectangle of the geometry.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @param crs        If specified, the result will be in this projection. Otherwise it will be in WGS84.\n   * @return\n   */\n  def bounds(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    featureRDD.map(t => {\n      (UUID.randomUUID().toString, (Geometry.bounds(t._2._1, crs), t._2._2))\n    })\n  }\n\n  /**\n   * Returns the centroid of geometry\n   *\n   * @param featureRDD the featureRDD to operate\n   * @param crs        If specified, the result will be in this projection. Otherwise it will be in WGS84.\n   * @return\n   */\n  def centroid(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    featureRDD.map(t => {\n      (UUID.randomUUID().toString, (Geometry.centroid(t._2._1, crs), t._2._2))\n    })\n  }\n\n  /**\n   * Returns the input buffered by a given distance.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @param distance   The distance of the buffering, which may be negative. If no projection is specified, the unit is meters.\n   * @param crs        If specified, the buffering will be performed in this projection and the distance will be interpreted as units of the coordinate system of this projection.\n   * @return\n   */\n  def buffer(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], distance: Double, crs: String = \"EPSG:3857\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    featureRDD.map(t => {\n      (UUID.randomUUID().toString, (Geometry.buffer(t._2._1, distance, crs), t._2._2))\n    })\n  }\n\n  /**\n   * Returns the convex hull of the given geometry.\n   *\n   * @param featureRDD featureRDD to operate\n   * @param crs        If specified, the result will be in this projection. Otherwise it will be in WGS84.\n   * @return\n   */\n  def convexHull(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    featureRDD.map(t => {\n      (UUID.randomUUID().toString, (Geometry.convexHull(t._2._1, crs), t._2._2))\n    })\n  }\n\n  /**\n   * Returns a GeoJSON-style array of the geometry's coordinates\n   *\n   * @param featureRDD the featureRDD to operate\n   * @return\n   */\n  def coordinates(featureRDD: RDD[(String, (Geometry, Map[String, Any]))]): String = {\n    val result: List[Array[Coordinate]] =featureRDD.map(t => {\n      t._2._1.getCoordinates\n    }).collect().toList\n\n    result.flatten.map(coordinate => s\"(${coordinate.x}, ${coordinate.y})\").mkString(\", \")\n  }\n\n  /**\n   * Transforms the geometry to a specific projection.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @param tarCrsCode target CRS\n   * @return\n   */\n  def reproject(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], tarCrsCode: String): RDD[(String, (Geometry, Map[String, Any]))] = {\n    featureRDD.map(t => {\n      (UUID.randomUUID().toString, (Geometry.reproject(t._2._1, tarCrsCode), t._2._2))\n    })\n  }\n\n  /**\n   * Returns whether the geometry is unbounded.\n   * if false, the geometry has no boundary; if true, the geometry has boundary\n   * only 0 dimension geometry has no boundary\n   *\n   * @param featureRDD\n   * @return\n   */\n  def isUnbounded(featureRDD: RDD[(String, (Geometry, Map[String, Any]))]): String = {\n    featureRDD.map(t => {\n      if (t._2._1.getBoundaryDimension < 0)\n        false\n      else\n        true\n    }).collect().toList.mkString\n  }\n\n  /**\n   * Returns the GeoJSON type of the geometry.\n   *\n   * @param featureRDD the featureRDD to opreate\n   * @return\n   */\n  def getType(featureRDD: RDD[(String, (Geometry, Map[String, Any]))]): String = {\n    featureRDD.map(t => {\n      t._2._1.getGeometryType\n    }).collect().toList.mkString\n  }\n\n  /**\n   * Returns the projection of the geometry.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @return\n   */\n  def projection(featureRDD: RDD[(String, (Geometry, Map[String, Any]))]): String = {\n    featureRDD.map(t => {\n      t._2._1.getSRID\n    }).collect().toList.mkString\n  }\n\n  /**\n   * Returns a GeoJSON string representation of the geometry.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @return\n   */\n  def toGeoJSONString(featureRDD: RDD[(String, (Geometry, Map[String, Any]))]): String = {\n    val data = featureRDD.map(t => {\n      (Geometry.toGeoJSONString(t._2._1), t._2._2)\n    }).collect().toList\n    val jsonObject = new JSONObject\n    val geoArray = new JSONArray()\n    for (feature <- data) {\n      val combinedObject = new JSONObject()\n      val coors = JSON.parseObject(feature._1)\n      val pro = new JSONObject()\n      feature._2.foreach(x => {\n        pro.put(x._1, x._2)\n      })\n      combinedObject.put(\"type\", \"Feature\")\n      combinedObject.put(\"geometry\", coors)\n      combinedObject.put(\"properties\", pro)\n      geoArray.add(combinedObject)\n    }\n\n    jsonObject.put(\"type\", \"FeatureCollection\")\n    jsonObject.put(\"features\", geoArray)\n    val geoJSONString: String = jsonObject.toJSONString()\n    geoJSONString\n  }\n\n  def saveJSONToServer(geoJSONString: String): String = {\n    val time = System.currentTimeMillis()\n    val host = GlobalConfig.QGISConf.QGIS_HOST\n    val userName = GlobalConfig.QGISConf.QGIS_USERNAME\n    val password = GlobalConfig.QGISConf.QGIS_PASSWORD\n    val port = GlobalConfig.QGISConf.QGIS_PORT\n\n   val outputVectorPath = s\"${GlobalConfig.Others.jsonSavePath}vector_${time}.json\"\n\n\n    // 创建PrintWriter对象\n    val writer: BufferedWriter = new BufferedWriter(new FileWriter(outputVectorPath))\n\n    // 写入JSON字符串\n    writer.write(geoJSONString)\n\n    // 关闭PrintWriter\n    writer.close()\n\n    versouSshUtil(host, userName, password, port)\n\n    val st = s\"scp  $outputVectorPath root@${GlobalConfig.Others.tomcatHost}:/home/oge/tomcat/apache-tomcat-8.5.57/webapps/oge_vector/vector_${time}.json\"\n\n    //本地测试使用代码\n//      val exitCode: Int = st.!\n//      if (exitCode == 0) {\n//        println(\"SCP command executed successfully.\")\n//      } else {\n//        println(s\"SCP command failed with exit code $exitCode.\")\n//      }\n\n      runCmd(st, \"UTF-8\")\n      println(s\"st = $st\")\n\n    val storageURL = s\"http://${GlobalConfig.Others.tomcatHost_public}/tomcat-vector/vector_\" + time + \".json\"\n\n    storageURL\n  }\n\n  /**\n   * get length of the feature RDD.\n   *\n   * @param featureRDD the feature RDD to compute\n   * @param crs        the crs for compute length\n   * @return\n   */\n  def length(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:3857\"): String = {\n    featureRDD.map(t => {\n      Geometry.length(t._2._1, crs)\n    }).collect().toList.mkString\n  }\n\n  /**\n   * Returns the list of geometries in a GeometryCollection, or a singleton list of the geometry for single geometries.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @return\n   */\n  //TODO:未写入json文件中\n  def geometries(featureRDD: RDD[(String, (Geometry, Map[String, Any]))]): RDD[(String, (List[Geometry], Map[String, Any]))] = {\n    featureRDD.map(t => {\n      var geomList: List[Geometry] = List.empty\n      val geomNum = t._2._1.getNumGeometries\n      var i = 0\n      for (i <- 0 until geomNum) {\n        geomList = geomList :+ t._2._1.getGeometryN(i)\n      }\n      (UUID.randomUUID().toString, (geomList, t._2._2))\n    })\n  }\n\n  /**\n   * Computes the union of all the elements of this geometry.\n   * only for GeometryCollection\n   *\n   * @param featureRDD the featureRDD to operate\n   * @param crs        If specified, the result will be in this projection. Otherwise it will be in WGS84.\n   * @return\n   */\n  def dissolve(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    featureRDD.map(t => {\n      (UUID.randomUUID().toString, (Geometry.dissolve(t._2._1, crs), t._2._2))\n    })\n  }\n\n  /**\n   * Returns true iff one geometry contains the other.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def contains(featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n               featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): String = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    Geometry.contains(geom1, geom2, crs).toString\n  }\n\n  /**\n   * Returns true iff one geometry is contained in the other.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def containedIn(featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n                  featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): String = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    Geometry.containedIn(geom1, geom2, crs).toString\n  }\n\n  /**\n   * Returns true iff the geometries are disjoint.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def disjoint(featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n               featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): String = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    Geometry.disjoint(geom1, geom2, crs).toString\n  }\n\n  /**\n   * Returns the minimum distance between two geometries.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:3857\n   * @return\n   */\n  def distance(featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n               featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:3857\"): String = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    Geometry.distance(geom1, geom2, crs).toString\n  }\n\n  /**\n   * Returns the result of subtracting the 'right' geometry from the 'left' geometry.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def difference(implicit sc: SparkContext, featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n                 featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    val res = Geometry.difference(geom1, geom2, crs)\n    feature(sc, res)\n  }\n\n  /**\n   * Returns the intersection of the two geometries.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def intersection(implicit sc: SparkContext, featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n                   featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    val res = Geometry.intersection(geom1, geom2, crs)\n    feature(sc, res)\n  }\n\n  /**\n   * Returns true iff the geometries intersect.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def intersects(featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n                 featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): String = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    Geometry.intersects(geom1, geom2, crs).toString\n  }\n\n  /**\n   * Returns the symmetric difference between two geometries.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def symmetricDifference(implicit sc: SparkContext, featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n                          featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    val res = Geometry.symmetricDifference(geom1, geom2, crs)\n    feature(sc, res)\n  }\n\n  /**\n   * Returns the union of the two geometries.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def union(implicit sc: SparkContext, featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n            featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], crs: String = \"EPSG:4326\"): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    val res = Geometry.union(geom1, geom2, crs)\n    feature(sc, res)\n  }\n\n  /**\n   * Returns true iff the geometries are within a specified distance.\n   * This is for geometry defined by user\n   *\n   * @param featureRDD1 the left featureRDD, it only has 1 element\n   * @param featureRDD2 the right featureRDD, it only has 1 element\n   * @param distance    he distance threshold.\n   * @param crs         The projection in which to perform the operation.  If not specified, the operation will be performed in EPSG:4326\n   * @return\n   */\n  def withDistance(featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n                   featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], distance: Double, crs: String = \"EPSG:3857\"): String = {\n    val geom1 = featureRDD1.first()._2._1\n    val geom2 = featureRDD2.first()._2._1\n    Geometry.withDistance(geom1, geom2, distance, crs).toString\n  }\n\n  /**\n   * Copies metadata properties from one element to another.\n   *\n   * @param featureRDD1 The object whose properties to override. it only has 1 element\n   * @param featureRDD2 The object from which to copy the properties. it only has 1 element\n   * @param properties  The properties to copy. If omitted, all properties are copied.\n   * @return\n   */\n  def copyProperties(featureRDD1: RDD[(String, (Geometry, Map[String, Any]))],\n                     featureRDD2: RDD[(String, (Geometry, Map[String, Any]))], properties: List[String] = null): RDD[(String, (Geometry, Map[String, Any]))] = {\n    var destnation = featureRDD1.first()._2._2\n    var source = featureRDD2.first()._2._2\n    if (properties == null || properties.isEmpty)\n      destnation = destnation ++ source\n    else {\n      for (property <- properties)\n        destnation += (property -> source(property))\n    }\n    featureRDD1.map(t => (t._1, (t._2._1, destnation)))\n  }\n\n  /**\n   * Extract a property from a feature.\n   *\n   * @param featureRDD The feature to extract the property from.\n   * @param property   The property to extract.\n   * @return\n   */\n  def get(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], property: String): List[Any] = {\n    featureRDD.map(t => t._2._2(property)).collect().toList\n  }\n\n  /**\n   * Extract a property from a feature. Return a number\n   *\n   * @param featureRDD The feature to extract the property from.\n   * @param property   The property to extract.\n   * @return\n   */\n  def getNumber(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], property: String): List[Double] = {\n    featureRDD.map(t => t._2._2(property).asInstanceOf[String].toDouble).collect().toList\n  }\n\n  /**\n   * Extract a property from a feature. Return a string\n   *\n   * @param featureRDD The feature to extract the property from.\n   * @param property   The property to extract.\n   * @return\n   */\n  def getString(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], property: String): List[String] = {\n    featureRDD.map(t => t._2._2(property).asInstanceOf[String]).collect().toList\n  }\n\n  /**\n   * Extract a property from a feature. Return a array, the element of array is String\n   *\n   * @param featureRDD The feature to extract the property from.\n   * @param property   The property to extract.\n   * @return\n   */\n  def getArray(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], property: String): List[Array[String]] = {\n    featureRDD.map(t => {\n      t._2._2(property).asInstanceOf[String].replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")\n    }).collect().toList\n  }\n\n  /**\n   * Returns the names of properties on this element.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @return\n   */\n  def propertyNames(featureRDD: RDD[(String, (Geometry, Map[String, Any]))]): String = {\n    featureRDD.map(t => t._2._2.keySet.toList).collect().toList.mkString(\",\")\n  }\n\n  /**\n   * Overrides one or more metadata properties of an Element.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @param property   the property to set. it is a json\n   * @return\n   */\n  def set(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], property: String): RDD[(String, (Geometry, Map[String, Any]))] = {\n    featureRDD.map(t => {\n      (t._1, (t._2._1, t._2._2 ++ getMapFromStr(property)))\n    })\n  }\n\n  /**\n   * Returns the feature, with the geometry replaced by the specified geometry.\n   *\n   * @param featureRDD the featureRDD to operate\n   * @param geom       the property to set. it is a json\n   * @return\n   */\n  def setGeometry(featureRDD: RDD[(String, (Geometry, Map[String, Any]))],\n                  geom: RDD[(String, (Geometry, Map[String, Any]))]): RDD[(String, (Geometry, Map[String, Any]))] = {\n    val geometry = geom.first()._2._1\n    featureRDD.map(t => {\n      (t._1, (geometry, t._2._2))\n    })\n  }\n\n  /**\n   * TODO: fix bug\n   * TODO: 简单克里金插值(奇异矩阵报错), modelType参数未使用，是否需要输入掩膜\n   *\n   * @param featureRDD\n   * @param propertyName\n   * @param modelType\n   * @return\n   */\n  //块金：nugget，基台：sill，变程：range\n  def simpleKriging(implicit sc: SparkContext, featureRDD: RDD[(String, (Geometry, Map[String, Any]))], propertyName: String, modelType: String) = {\n    //Kriging Interpolation for PointsRDD\n    val extents = featureRDD.map(t => {\n      val coor = t._2._1.getCoordinate\n      (coor.x, coor.y, coor.x, coor.y)\n    }).reduce((coor1, coor2) => {\n      (min(coor1._1, coor2._1), min(coor1._2, coor2._2), max(coor1._3, coor2._3), max(coor1._4, coor2._4))\n    })\n    val extent = Extent(extents._1, extents._2, extents._3, extents._4)\n    val rows = 256\n    val cols = 256\n    val rasterExtent = RasterExtent(extent, cols, rows)\n    val points: Array[PointFeature[Double]] = featureRDD.map(t => {\n      val p = vector.Point(t._2._1.getCoordinate)\n      //TODO 直接转换为Double类型会报错\n      //      var data = t._2._2(propertyName).asInstanceOf[Double]\n      var data = t._2._2(propertyName).asInstanceOf[String].toDouble\n      if (data < 0) {\n        data = 100\n      }\n      PointFeature(p, data)\n    }).collect()\n    println()\n    val sv: Semivariogram = NonLinearSemivariogram(points, 30000, 0, Spherical)\n    val method = new SimpleKrigingMethods {\n      //TODO fix bug 简单克里金插值(奇异矩阵报错)\n      override def self: Traversable[PointFeature[Double]] = points\n    }\n    val originCoverage = method.simpleKriging(rasterExtent, sv)\n\n\n    val tl = TileLayout(10, 10, 256, 256)\n    val ld = LayoutDefinition(extent, tl)\n    val crs = geotrellis.proj4.CRS.fromEpsgCode(featureRDD.first()._2._1.getSRID)\n    val time = System.currentTimeMillis()\n    val bounds = Bounds(SpaceTimeKey(0, 0, time), SpaceTimeKey(0, 0, time))\n    //TODO cellType的定义\n    val cellType = originCoverage.cellType\n    val tileLayerMetadata = TileLayerMetadata(cellType, ld, extent, crs, bounds)\n\n    originCoverage.toArrayTile()\n    var list: List[Tile] = List.empty\n    list = list :+ originCoverage\n    val tileRDD = sc.parallelize(list)\n    val imageRDD = tileRDD.map(t => {\n      val k = cn.entity.SpaceTimeBandKey(SpaceTimeKey(0, 0, time), ListBuffer(\"interpolation\"))\n      val v = MultibandTile(t)\n      (k, v)\n    })\n\n    (imageRDD, tileLayerMetadata)\n  }\n\n  /**\n   * 反距离加权插值\n   *\n   * @param sc\n   * @param featureRDD\n   * @param propertyName\n   * @param maskGeom\n   * @return\n   */\n  def inverseDistanceWeighted(implicit sc: SparkContext, featureRDD: RDD[(String, (Geometry, Map[String, Any]))],\n                              propertyName: String, maskGeom: RDD[(String, (Geometry, Map[String, Any]))]): (RDD[(SpaceTimeBandKey, MultibandTile)], TileLayerMetadata[SpaceTimeKey]) = {\n    val t1 = System.currentTimeMillis()\n    val extents = featureRDD.map(t => {\n      val coor = t._2._1.getCoordinate\n      (coor.x, coor.y, coor.x, coor.y)\n    }).reduce((coor1, coor2) => {\n      (min(coor1._1, coor2._1), min(coor1._2, coor2._2), max(coor1._3, coor2._3), max(coor1._4, coor2._4))\n    })\n    val extent = Extent(extents._1, extents._2, extents._3, extents._4)\n    val t2 = System.currentTimeMillis()\n    println(\"获取点数据extent的时间：\" + (t2 - t1) / 1000)\n    println(\"extent:\" + extent)\n    val rows = 256\n    val cols = 256\n    val rasterExtent = RasterExtent(extent, cols, rows)\n    val points: Array[PointFeature[Double]] = featureRDD.map(t => {\n      //      val p=vector.Point(t._2._1.getCoordinate)\n      val p = t._2._1.asInstanceOf[Point]\n      var data = t._2._2(propertyName).asInstanceOf[String].toDouble\n      if (data < 0) {\n        data = 100\n      }\n      PointFeature(p, data)\n    }).collect()\n    val t3 = System.currentTimeMillis()\n    println(\"构建PointFeature[]的时间：\" + (t3 - t2) / 1000)\n    val rasterTile = InverseDistanceWeighted(points, rasterExtent)\n    val t4 = System.currentTimeMillis()\n    println(\"调用Geotrellis提供的IDW函数的时间：\" + (t4 - t3) / 1000)\n    println(\"初步空间插值的时间（结果未剪裁）：\" + (t4 - t1) / 1000)\n\n    //    val maskPolygon=maskGeom.map(t=>t._2._1).reduce((x,y)=>{Geometry.union(x,y)})\n    val maskPolygon = maskGeom.map(t => t._2._1).first()\n    val t5 = System.currentTimeMillis()\n    println(\"从RDD获取中国国界的时间：\" + (t5 - t4) / 1000)\n    val maskRaster = rasterTile.mask(maskPolygon)\n\n    //    maskRaster.tile.renderPng(ColorRamps.BlueToOrange).write(\"D:\\\\Apersonal\\\\PostStu\\\\Project\\\\luojiaEE\\\\stage2\\\\code2\\\\testMask.png\")\n    val t6 = System.currentTimeMillis()\n    println(\"裁剪结果的时间：\" + (t6 - t5) / 1000)\n    //maskRaster.tile.renderPng(ColorRamps.BlueToOrange).write(\"D:\\\\Apersonal\\\\PostStu\\\\Project\\\\luojiaEE\\\\stage2\\\\code2\\\\testMask.png\")\n\n\n    val tl = TileLayout(1, 1, 256, 256)\n    val ld = LayoutDefinition(extent, tl)\n    val crs = geotrellis.proj4.CRS.fromEpsgCode(featureRDD.first()._2._1.getSRID)\n    val time = System.currentTimeMillis()\n    val bounds = Bounds(SpaceTimeKey(0, 0, time), SpaceTimeKey(0, 0, time))\n    //TODO cellType的定义\n    val cellType = maskRaster.tile.cellType\n    //      val cellType = DoubleCellType\n    val tileLayerMetadata = TileLayerMetadata(cellType, ld, extent, crs, bounds)\n    var list: List[Tile] = List.empty\n    list = list :+ maskRaster.tile\n    val tileRDD = sc.parallelize(list)\n\n    val imageRDD = tileRDD.map(t => {\n      val k = cn.entity.SpaceTimeBandKey(SpaceTimeKey(0, 0, time), ListBuffer(\"interpolation\"))\n      val v = MultibandTile(t)\n      (k, v)\n    })\n    val t7 = System.currentTimeMillis()\n    println(\"构造ImageRDD时间：\" + (t7 - t6) / 1000)\n    println(\"完整空间插值函数的时间：\" + (t7 - t1) / 1000)\n    (imageRDD, tileLayerMetadata)\n  }\n\n\n  /**\n   * 根据给定的属性值，对featureRDD进行栅格化\n   *\n   * @param featureRDD\n   * @param propertyName\n   * @return\n   */\n  def rasterize(featureRDD: RDD[(String, (Geometry, Map[String, Any]))], propertyName: String) = {\n\n    val extents = featureRDD.map(t => {\n      val coor = t._2._1.getCoordinate\n      //      val coorArray = t._2._1.getCoordinates\n      //      for (item <- coorArray) {\n      //\n      //      }\n      (coor.x, coor.y, coor.x, coor.y)\n    }).reduce((coor1, coor2) => {\n      (min(coor1._1, coor2._1), min(coor1._2, coor2._2), max(coor1._3, coor2._3), max(coor1._4, coor2._4))\n    })\n    val extent = Extent(extents._1, extents._2, extents._3, extents._4)\n\n\n    //TODO:tileLayOut的定义\n    val tl = TileLayout(1, 1, 256, 256)\n    val ld = LayoutDefinition(extent, tl)\n    val crs = geotrellis.proj4.CRS.fromEpsgCode(featureRDD.first()._2._1.getSRID)\n    val time = System.currentTimeMillis()\n    val bounds = Bounds(SpaceTimeKey(0, 0, time), SpaceTimeKey(0, 0, time))\n    //TODO cellType的定义\n    val cellType = DoubleCellType\n    val tileLayerMetadata = TileLayerMetadata(cellType, ld, extent, crs, bounds)\n\n\n    val featureRDDforRaster: RDD[vector.Feature[Geometry, Double]] = featureRDD.map(t => {\n      //TODO 直接转换为Double类型会报错\n      //val data = t._2._2(propertyName).asInstanceOf[Double]\n      val data = t._2._2(propertyName).asInstanceOf[String].toDouble\n      val feature = new vector.Feature[Geometry, Double](t._2._1, data)\n      feature\n    })\n    val originCoverage = featureRDDforRaster.rasterize(cellType, ld)\n\n\n    //    //TODO 栅格化（测试）\n    //    val rasterRDD = featureRDD.map { case (featureId, (geometry, properties)) =>\n    //      val rasterizedData = Rasterizer.rasterize(geometry, RasterExtent(extent,256,256)){\n    //        (x: Int, y: Int) => properties.get(propertyName) match{\n    //          case Some(value: String) => properties.asInstanceOf[String].toInt// Use the property value as the raster value\n    //          case _ => 5000 // Set Nodata value for pixels without the property value\n    //        }\n    //      }\n    //      (featureId, rasterizedData)\n    //    }\n\n\n    val imageRDD = originCoverage.map(t => {\n      val k = cn.entity.SpaceTimeBandKey(SpaceTimeKey(0, 0, time), ListBuffer(\"interpolation\"))\n      val v = MultibandTile(t._2)\n      (k, v)\n    })\n\n    (imageRDD, tileLayerMetadata)\n  }\n\n  def visualize(feature: RDD[(String, (Geometry, Map[String, Any]))],color:List[String],attribute:String): Unit = {\n    val geoJson = new JSONObject\n    val render = new JSONObject\n    val geoJSONString = toGeoJSONString(feature)\n    val url = saveJSONToServer(geoJSONString)\n    geoJson.put(Trigger.layerName, url)\n    val colorArray = new JSONArray()\n    for (st <- color) {\n      colorArray.add(st)\n    }\n    render.put(\"color\", colorArray)\n    render.put(\"attribute\", attribute)\n    geoJson.put(\"render\", render)\n    PostSender.shelvePost(\"vector\",geoJson)\n  }\n\n\n  // 下载用户上传的geojson文件\n  def loadFeatureFromUpload(implicit sc: SparkContext, featureId: String, userID: String, dagId: String, crs: String = \"EPSG:4326\"): (RDD[(String, (Geometry, Map[String, Any]))]) = {\n    var path: String = new String()\n    if (featureId.endsWith(\".geojson\")) {\n      path = s\"${userID}/$featureId\"\n    } else {\n      path = s\"$userID/$featureId.geojson\"\n    }\n\n\n    val tempPath = GlobalConfig.Others.tempFilePath\n    val filePath = s\"$tempPath${dagId}_${Trigger.file_id}.geojson\"\n\n    MinIOUtil.MinIODownload(\"oge-user\", path, filePath)\n    println(s\"Download $filePath\")\n    val temp = Source.fromFile(filePath).mkString\n    val feature = geometry(sc, temp,crs)\n    feature\n  }\n\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/whu/edu/cn/oge/Feature.scala b/src/main/scala/whu/edu/cn/oge/Feature.scala
--- a/src/main/scala/whu/edu/cn/oge/Feature.scala	(revision 6708fb1f308d32fc9398f21ff322c30fa2156943)
+++ b/src/main/scala/whu/edu/cn/oge/Feature.scala	(date 1723879072376)
@@ -571,7 +571,7 @@
 
     versouSshUtil(host, userName, password, port)
 
-    val st = s"scp  $outputVectorPath root@${GlobalConfig.Others.tomcatHost}:/home/oge/tomcat/apache-tomcat-8.5.57/webapps/oge_vector/vector_${time}.json"
+    val st = s"scp $outputVectorPath oge@${GlobalConfig.Others.tomcatHost}:/home/oge/tomcat/apache-tomcat-8.5.57/webapps/oge_vector/vector_${time}.json"
 
     //本地测试使用代码
 //      val exitCode: Int = st.!
Index: src/main/resources/config.yaml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>DagBootConf: # dag-boot 服务根路径\n  DAG_ROOT_URL: \"http://192.168.32.5:8085/oge-dag-22\"\n\n\nRedisConf:\n  JEDIS_HOST: \"125.220.153.26\"\n  JEDIS_PORT: 6379\n  JEDIS_PWD: \"ypfamily608\"\n  # Redis 超时时间\n  REDIS_CACHE_TTL: 120\n\nMinioConf:\n  # MinIO 基础配置\n  MINIO_ENDPOINT: \"http://125.220.153.22:9006\"\n  MINIO_ACCESS_KEY: \"rssample\"\n  MINIO_SECRET_KEY: \"ypfamily608\"\n  MINIO_BUCKET_NAME: \"oge\"\n  MINIO_HEAD_SIZE: 5000000\n  MINIO_MAX_CONNECTIONS: 10000\n\nPostgreSqlConf:\n  # PostgreSQL 基础配置\n  POSTGRESQL_URL: \"jdbc:postgresql://120.48.44.57:3306/oge\"\n  POSTGRESQL_DRIVER: \"org.postgresql.Driver\"\n  POSTGRESQL_USER: \"oge\"\n  POSTGRESQL_PWD: \"ypfamily608\"\n  POSTGRESQL_MAX_RETRIES: 3\n  POSTGRESQL_RETRY_DELAY: 500\n\n# GcConst\nGcConf:\n  localDataRoot: \"/home/geocube/tomcat8/apache-tomcat-8.5.57/webapps/data/gdc_api/\"\n  httpDataRoot: \"http://125.220.153.26:8093/data/gdc_api/\"\n  localHtmlRoot: \"/home/geocube/tomcat8/apache-tomcat-8.5.57/webapps/html/\"\n  algorithmJson: \"/home/geocube/kernel/geocube-core/tb19/process_description.json\"\n\nQGISConf:\n  QGIS_DATA: \"/home/ogeStorage/algorithmData/\"\n  QGIS_ALGORITHMCODE: \"cd /home/geocube/oge/oge-server/dag-boot/qgis;\"\n  QGIS_HOST: \"10.101.240.10\"\n  QGIS_USERNAME:  \"root\"\n  QGIS_PASSWORD:  \"ypfamily\"\n  QGIS_PORT: 22\n  QGIS_PYTHON: \"/home/ogeStorage/miniconda3/bin/python\"\n  QGIS_RS : \"/home/geocube/oge/oge-server/dag-boot/qgis/rs/\"\n\nOthers:\n  jsonAlgorithms: \"/root/storage/algorithms_ogc.json\" # 存储json解析文件地址\n  tempFilePath: \"/mnt/storage/temp/\" # 各类临时文件的地址\n  tmsPath: \"http://120.48.147.38/api/oge-tms-png/\" # tms服务url\n  ontheFlyStorage: \"/mnt/storage/on-the-fly/\" # tms瓦片存储地址\n  jsonSavePath: \"/mnt/storage/algorithmData/\" # geojson临时存储地址\n  bucketName : \"ogebos\"
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/resources/config.yaml b/src/main/resources/config.yaml
--- a/src/main/resources/config.yaml	(revision 6708fb1f308d32fc9398f21ff322c30fa2156943)
+++ b/src/main/resources/config.yaml	(date 1723879072378)
@@ -50,4 +50,4 @@
   tmsPath: "http://120.48.147.38/api/oge-tms-png/" # tms服务url
   ontheFlyStorage: "/mnt/storage/on-the-fly/" # tms瓦片存储地址
   jsonSavePath: "/mnt/storage/algorithmData/" # geojson临时存储地址
-  bucketName : "ogebos"
\ No newline at end of file
+  bucketName : "ogebos"
